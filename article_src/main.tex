\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1,T2A]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
% \usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage{graphicx}
\usepackage[square,numbers]{natbib}
\usepackage{doi}
% \usepackage{cite}
\usepackage[english, russian]{babel}


\title{Измерение уровня галлюцинаций в LLM}

% Here you can change the date presented in the paper title
\date{10 декабря 2023}
% Or remove it
%\date{}

\author{{Дмитрий Тронин} \\
	22 МАГ ИАД\\
	Факультет информатики, математики \\ и компьютерных наук \\
	ВШЭ НН
}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{Д. Тронин}
\renewcommand{\undertitle}{}
\renewcommand{\shorttitle}{Измерение уровня галлюцинаций в LLM}

\begin{document}
\maketitle

\begin{abstract}
    Несмотря на огромные возможности LLM, данные модели обладают большим недостатком: их ответам нельзя полностью доверять. Экспериментально была замечена склонностью такого вида нейронных моделей к генерации ложной информации (галлюцинаций) в контекстах, где ожидался правдивый ответ. Поэтому при сравнении различных LLM важно также оценивать уровень галлюцинаций при их работе. В данной работе предлагается модифицированная методика измерения уровня галлюцинаций в LLM, а также приводится сравнение нескольких популярных моделей.
\end{abstract}

% keywords can be removed
\keywords{LLM \and Галлюцинаций}


\section{Введение}
В последнее время наблюдается активный рост в развитии и использовании больших языков моделей (Large Language Model, LLM). Эти модели, представляющие разновидность нейронных сетей, демонстрируют способность решать широкий спектр различных задач. В связи практически ежедневно появляются новые варианты их применения на практике.

Однако, несмотря на их большие возможности, необходимо с осторожностью подходить к использованию больших языков моделей из-за их склонности к галлюцинациям. Из-за сложности и множества различных проявлений галлюцинаций в академической среде не сформировалось общепринятое определение данного феномена.

В ходе данной работы использовалось следующее определение: «Галлюцинация – это ответ LLM, которые нарушает инструкции, данные человеком»  \cite{du2023quantifying}. Данное определение покрывает различные варианты использования LLM от получения исторический справки до создания художественных произведений.


\section{Обоснование методологии}
Согласно подходу, предложенному в \cite{du2023quantifying}, вместо того, чтобы рассматривать уровень галлюцинирования при выполнение различных NLP задач, мы рассматриваем LLM как черный ящик. Благодаря тому, что языковые модели могут выполнять множество различных задач, предлагается оценка способностей модели на основе уровней с учетом исследований психологии человека. Предполагается, что недостаточные способности на определенном уровне приведет к генерации галлюцинаций.

В качестве уровней LLM мы рассматривали следующие компетенции:
\begin{enumerate}
    \item Понимание естественного языка

          Лексические, синтаксические, морфологические знания и значения слов позволяют модели корректно распознавать запросы пользователя. Данный уровень является основой для работы LLM.

    \item Общие знания об окружающем мире

          Знания об предметах окружающего мира, взаимоотношения и связи между ними, событиях позволяют модели рассуждать на основе здравого смысла, что является необходимым для понимания материального мира и человеческого общества.

    \item Абстрактное мышление

          Понимание абстрактных понятий и их связей позволяет модели делать выводы на основе имеющихся фактов. Данная способность является основой для высших когнитивных способностей, таких как планирование, решение задач и принятие решений.
\end{enumerate}

Основным преимуществом данного подхода является его универсальность. На основе понимания естественного языка, знаниях об окружающем мире и способности к абстрактному мышлению LLM способна решать широкий спектр NLP задач.

\section{Методология}
\subsection*{Понимание естественного языка}
Для проверки способности LLM понимать естественный язык мы предлагаем задачу перевода юридических текстов, для которых существую версии на 2х языках. Юридические тексты написаны так, чтобы точно передавать значение. В таком случае вероятность нескольких возможных эквивалентных переводов мало, поэтому можно считать иной перевод отклонением, а значит галлюцинацией.

\subsection*{Общие знания об окружающем мире}
Для проверки общих знаний об окружающем мире мы предлагаем задачу описания редких слов. За счет того, что слово мало встречалось в обучающей выборке, вероятность галлюцинаций растет.

\subsection*{Абстрактное мышление}
Для проверки способности LLM к абстрактному мышлению мы предлагаем задачу логического вывода на основе приведенных фактов, которые не связаны с материальным миром. Явное использование только приведенных фактов позволит отличить ситуацию, в которой модель не имеет необходимых фактов об окружающем мире, от ситуации, в котором модель имеет низкий уровень абстрактного мышления. Факты сформулированны таким образом, что логический вывод можно произвести с помощью бинарной логики.

\section{Экспериментальное исследование}
В качестве моделей для экспериментов мы использовали:
\begin{enumerate}

    \item Сбер GigaChat \cite{gigachat}
    \item OpenAI ChatGPT-3.5 \cite{chatgpt}
    \item Anthropic Claude 2 \cite{claude}
\end{enumerate}

При проведении исследования каждой LLM было задано 20 запросов на каждом уровне компетенций. Каждый запрос задавался с пустым контекстом. Таким образом все ответы модели независимы. Слова отбирались из последних 10\% ранжированного по встречаемости списка.

Определение корректности сгенерированного LLM ответа производилось экспертом на основе общедоступной информации и эталонного ответа из тестового набора данных.

\subsection*{Понимание естественного языка}
В качестве тестового набора данных для перевода юридических текстов использовалась статьи Всеобщая декларация прав человека ООН на английском \cite{declaration_eng} и русском \cite{declaration_rus} языках.

Запрос: \\
\texttt{Translate the next paragraphs into Russian. Be as precise in terminology as possible. \\
    <текст статьи на английском>}

Результаты представлены в таблице \ref{tab:natural_language}.

\begin{table}[ht]
    \centering
    \begin{tabular}{lrrr}
        \toprule
                & \multicolumn{3}{c}{Английский язык}                          \\
        \cmidrule(r){2-4}
                & GigaChat                            & ChatGPT-3.5 & Claude 2 \\
        \midrule
        Верно   & 7                                   & 11          & 18       \\
        Неверно & 13                                  & 9           & 2        \\
        \bottomrule
    \end{tabular}
    \caption{Результаты исследования понимания естественного языка}
    \label{tab:natural_language}
\end{table}

Наблюдения на основе исследования:
\begin{enumerate}
    \item GigaChat достаточно часто генерирует фразы, которые звучат ненатурально (запросы №1, 3, 11, 15, 19)
    \item Все модели иногда добавляют дополнительные комментарии в ответ
    \item GigaChat иногда не переводит текст, а возвращает оригинальное обращение (запрос №9)
    \item GigaChat и ChatGPT-3.5 часто неправильно переводят юридические термины.
    \item Claude 2 очень часто полностью повторяет эталонный ответ. Возможно модель обучалось на используемом тестовом наборе данных.
\end{enumerate}

Согласно исследованию GigaChat хуже всего справляется с задачей перевода юридического текста, далее по качеству стоит ChatGPT-3.5, и наиболее качественно перевод генерирует Claude 2.

\subsection*{Общие знания об окружающем мире}

В качестве тестового набора данных использовался частотные словари английского \cite{davies2013frequency} и русского \cite{rus} языка.

Запрос:
\begin{itemize}
    \item \texttt{Can you explain what is <понятие>?}
    \item \texttt{Можешь рассказать, что такое <понятие>?}
\end{itemize}

Результаты представлены в таблице \ref{tab:common_sense}.


\begin{table}[ht]
    \centering
    \begin{tabular}{lrrr}
        \toprule
                & \multicolumn{3}{c}{Английский язык}                          \\
        \cmidrule(r){2-4}
                & GigaChat                            & ChatGPT-3.5 & Claude 2 \\
        \midrule
        Верно   & 14                                  & 18          & 19       \\
        Неверно & 6                                   & 2           & 1        \\
        \midrule
                & \multicolumn{3}{c}{Русский язык}                             \\
        \cmidrule(r){2-4}
                & GigaChat                            & ChatGPT-3.5 & Claude 2 \\
        \midrule
        Верно   & 15                                  &             & 15       \\
        Неверно & 5                                   &             & 5        \\
        \bottomrule
    \end{tabular}
    \caption{Результаты исследования уровня знаний об окружающем мире}
    \label{tab:common_sense}
\end{table}

Наблюдения на основе исследования на английском языке:
\begin{enumerate}
    \item При прочих равных GhatGPT-3.5 и Clade 2 генерируют более длинные ответы.
    \item GigaChat иногда отказывается отвечать на обращение пользователя (запросы №6, 14). Данное являение может быть связанно с внутренними правилами и ограничениями вывода результатов генерации.
    \item GigaChat иногда забывает язык, на котором было обращение, и отвечает на русском языке (запрос №17).
    \item Все модели при запросе объяснения слова ''billon'' (англ. низкопробное золото или серебро) сгенерировали объяснение слова ''billion'' (англ. миллиард). Это может быть связанно с внутренней обработкой опечаток.
\end{enumerate}

Согласно исследованию GigaChat имеет значительно меньшие знания об окружающем мире на английском языке, чем ChatGPT-3.5 и Claude 2.

Наблюдения на основе исследования на русском языке:
\begin{enumerate}
    \item Claude 2 иногда отказывается отвечать на обращение пользователя (запрос №4, 7).
\end{enumerate}

Согласно исследованию уровень знаний об окружающем мире на русском языке у GigaChat и Claude 2 примерно одинаков.

При сравнении случаев английского и русского языка видим, что число галлюцинаций Claude 2 на русском языке растет.

\subsection*{Абстрактное мышление}
В качестве тестового набора данных для английского языка использовался открытый датасет \texttt{ruletaker-depth-3ext} из статьи \cite{ruletaker}.

В качестве тестового набора данных для русского языка использовались те же запросы, переведенные на русский язык. При переводе особое внимание было уделено сохранению однозначности признаков в разных фактов, в случае когда английское слово имеет несколько смыслов (напр. ''red''  можно перевести как красный и рыжий).

Запрос:
\begin{itemize}
    \item \texttt{Given some premises, conduct reasoning to answer whether the given query is true, false or unknown. \\ Premises: <некоторые факты> \\
              Query: <вопрос>}
    \item \texttt{Учитывая некоторые предпосылки, проведите рассуждения, чтобы ответить, является ли данный запрос истинным, ложным или неизвестным. \\ Предпосылки: <некоторые факты> \\
              Запрос: <вопрос>}
\end{itemize}

Результаты представлены в таблице \ref{tab:abstract_reasoning}.


\begin{table}[ht]
    \centering
    \begin{tabular}{lrrr}
        \toprule
                & \multicolumn{3}{c}{Английский язык}                          \\
        \cmidrule(r){2-4}
                & GigaChat                            & ChatGPT-3.5 & Claude 2 \\
        \midrule
        Верно   & 8                                   & 12          & 18       \\
        Неверно & 12                                  & 8           & 2        \\
        \midrule
                & \multicolumn{3}{c}{Русский язык}                             \\
        \cmidrule(r){2-4}
                & GigaChat                            & ChatGPT-3.5 & Claude 2 \\
        \midrule
        Верно   & 8                                   &             & 15       \\
        Неверно & 12                                  &             & 5        \\
        \bottomrule
    \end{tabular}
    \caption{Результаты исследования способности к абстрактному мышлению}
    \label{tab:abstract_reasoning}
\end{table}

Наблюдения на основе исследования на английском языке:
\begin{enumerate}
    \item GigaChat иногда ошибается в тривиальных случаях, когда ответ выводится из 1 факта (запросы №2, 5, 7, 15)
    \item ChatGPT-3.5 и Claude 2 лучше следуют запросу, так как явно генерируют цепочку размышлений.
    \item ChatGPT-3.5 и Claude 2 чаще генерирует неверный ответ с ростом глубины цепочки размышлений (количестве использованных фактов, для корректного логического вывода).
\end{enumerate}

Согласно исследованию GigaChat имеет самую низкую способность к абстрактному мышлению на английском языке, далее по качеству стоит ChatGPT-3.5, и наиболее качественно перевод генерирует Claude 2.

Наблюдения на основе исследования на русском языке:
\begin{enumerate}
    \item GigaChat иногда ошибается в тривиальных случаях, когда ответ выводится из 1 факта (запросы №1, 3, 7).
    \item Обе модели точно следуют запросу и генерируют цепочку размышлений.
\end{enumerate}

Согласно исследованию GigaChat имеет более низкую способность к абстрактному мышлению на русском языке, далее по качеству стоит ChatGPT-3.5, и наиболее качественно перевод генерирует Claude 2.

При сравнении случаев английского и русского языка видим, что число галлюцинаций Claude 2 на русском языке растет.

\section{Выводы экспериментального исследования}
По результатам экспериментального исследования на всех уровнях мышления соблюдается следующий порядок (от большего числа галлюцинаций к большему):
\begin{enumerate}
    \item GigaChat
    \item ChatGPT-3.5
    \item Claude 2
\end{enumerate}

Интересно заметить, что использование запросов на русском языке снижает качество работы Claude 2, но не повышает качество GigaChat.

\section{Пути развития работы}
В качестве развития данной работы мы видим следующие направления:
\begin{itemize}
    \item увеличение числа запросов к моделям
    \item более подробное исследование способности к абстрактному мышлению с учетом разной глубины логической цепочки и различных способах логического вывода
    \item инжиниринг запросов к LLM для увеличения качества
\end{itemize}

\bibliographystyle{acm}
\bibliography{references}

\end{document}
